{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_learning_phase(True)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "K.set_learning_phase(True)\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_savedir = '/home/put_data/moth/code/cmchang/5_fold/'\n",
    "FLAG_sfold = 5\n",
    "FLAG_learning_rate = 2e-5\n",
    "idx_fold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FLAG_savedir, 'Y_multilabel_dict.pickle'), 'rb') as handle:\n",
    "    Y_dict = pickle.load(handle)\n",
    "    \n",
    "with open(os.path.join(FLAG_savedir, 'Y_num_mapping.pickle'), 'rb') as handle:\n",
    "    Y_num_mapping = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_model_save = '/home/put_data/moth/code/cmchang/TF_center_resnet_fold_{}_{}'.format(datetime.now().strftime('%Y%m%d'), idx_fold)\n",
    "if not os.path.exists(FLAG_model_save):\n",
    "    os.makedirs(FLAG_model_save)\n",
    "    print('make a directory: {}'.format(FLAG_model_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape: (19888, 9), Ytrain.shape: (19888, 5)\n",
      "Xtest.shape: (5387, 9), Ytest.shape: (5387, 5)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = pd.read_csv(os.path.join(FLAG_savedir, 'train_fold_{0}.csv'.format(idx_fold)))\n",
    "Ytrain = np.vstack(Xtrain['Species'].apply(lambda x: Y_dict[x]))\n",
    "Mtrain = np.vstack(Xtrain['Species'].apply(lambda x: Y_num_mapping[x]))\n",
    "\n",
    "Xtest = pd.read_csv(os.path.join(FLAG_savedir, 'test_fold_{0}.csv'.format(idx_fold)))\n",
    "Ytest = np.vstack(Xtest['Species'].apply(lambda x: Y_dict[x]))\n",
    "Mtest = np.vstack(Xtest['Species'].apply(lambda x: Y_num_mapping[x]))\n",
    "\n",
    "print('Xtrain.shape: {0}, Ytrain.shape: {1}'.format(Xtrain.shape, Ytrain.shape))\n",
    "print('Xtest.shape: {0}, Ytest.shape: {1}'.format(Xtest.shape, Ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, center_IDs=None, batch_size=32, dim=(256,256,3), n_classes=10, shuffle=True, img_preprocess=None, img_aug = None):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.center_IDs = center_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.indexes = list(range(0, len(self.list_IDs)))\n",
    "        self.img_aug = img_aug\n",
    "        self.img_preprocess = img_preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=int)\n",
    "        M = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(indexes):\n",
    "\n",
    "            # Store sample\n",
    "            X[i,] = io.imread(self.list_IDs[ID]).astype(float)\n",
    "            \n",
    "            # Store class\n",
    "            Y[i,] = self.labels[ID]\n",
    "        \n",
    "        X = self.__data_preprocess(X)\n",
    "        \n",
    "        if self.img_aug is not None:\n",
    "            X = self.img_aug.augment_images(X)\n",
    "        \n",
    "        if self.center_IDs is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            for i, ID in enumerate(indexes):\n",
    "                M[i] = self.center_IDs[ID]\n",
    "            return X,Y,M\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_preprocess(self, img):\n",
    "        if self.img_preprocess is None:\n",
    "            processed_img = img/255.0\n",
    "        else:\n",
    "            processed_img = self.img_preprocess(img)\n",
    "        return processed_img        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.8, aug)\n",
    "augseq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # horizontally flip 50% of the images\n",
    "    sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(-30, 30), # rotate by -45 to +45 degrees\n",
    "            cval=255 # if mode is constant, use a cval between 0 and 255\n",
    "        ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_shape = (256, 256, 3)\n",
    "n_classes = Ytest.shape[1]\n",
    "batch_size = 32\n",
    "n_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "class myResNet(object):\n",
    "    def __init__(self, input_shape=(256,256,3), n_classes=5, n_hidden=1000, scope_name=\"model\"):\n",
    "        self.input_shape = (None, *input_shape)\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hidden = n_hidden\n",
    "        self.scope_name = scope_name\n",
    "    \n",
    "    def build(self, centers=None, lambda_c = 0.0, keep_prob=1.0):\n",
    "        with tf.Session() as sess:\n",
    "            with tf.variable_scope(self.scope_name):\n",
    "                self.x = tf.placeholder(shape=self.input_shape, dtype=tf.float32)\n",
    "                self.y = tf.placeholder(shape=(None, self.n_classes), dtype=tf.float32) # one-hot encoding\n",
    "                self.is_train = tf.placeholder(tf.bool)\n",
    "\n",
    "                with tf.variable_scope(\"ResNet\"):\n",
    "                    extractor = tf.contrib.keras.applications.ResNet50(input_tensor=self.x, include_top=False, weights='imagenet', pooling='avg')\n",
    "                self.feature = extractor.output\n",
    "                feature_shape = self.feature.shape.as_list()\n",
    "\n",
    "                self.pretrained_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.scope_name+'/ResNet')\n",
    "                with tempfile.NamedTemporaryFile() as f:\n",
    "                    self.tf_checkpoint_path = tf.train.Saver(self.pretrained_weights).save(sess, f.name)\n",
    "                \n",
    "                conv_output = self.dropout_layer(self.feature, keep_prob=keep_prob)\n",
    "                \n",
    "                fc1_W = tf.get_variable(shape=(feature_shape[1], self.n_classes), initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=\"fc1_W\", dtype=tf.float32)\n",
    "                fc1_b = tf.get_variable(shape=(self.n_classes,), initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=\"fc1_b\", dtype=tf.float32)\n",
    "                logits = tf.nn.bias_add(tf.matmul(conv_output, fc1_W), fc1_b, name='logits')\n",
    "                # fc1_output = tf.nn.bias_add(tf.matmul(conv_output, fc1_W), fc1_b, name='fc1_output')\n",
    "                # fc1_output = tf.nn.relu(fc1_output)\n",
    "                \n",
    "\n",
    "#                 fc2_W = tf.get_variable(shape=(self.n_hidden, self.n_classes), initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=\"fc2_W\", dtype=tf.float32)\n",
    "#                 fc2_b = tf.get_variable(shape=(self.n_classes,), initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=\"fc2_b\", dtype=tf.float32)\n",
    "#                 logits = tf.nn.bias_add(tf.matmul(fc1_output, fc2_W), fc2_b, name='logits')\n",
    "\n",
    "                self.probs = tf.nn.sigmoid(logits, name='probs')\n",
    "                self.ce_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=self.y))\n",
    "\n",
    "                self.para_dict = { l.name: l.output for l in extractor.layers }\n",
    "#                 self.para_dict.update({'fc_1': [fc1_W, fc1_b], 'fc_2': [fc2_W, fc2_b]})\n",
    "                self.para_dict.update({'fc_1': [fc1_W, fc1_b]})\n",
    "\n",
    "                if centers is not None:\n",
    "                    print(\"incorporate center_loss\")\n",
    "                    self.index = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "                    if isinstance(centers, tuple):\n",
    "                        self.centers = tf.get_variable(shape=centers, initializer=tf.zeros_initializer(), name=\"centers\", dtype=tf.float32, trainable=False)\n",
    "                    elif isinstance(centers, np.ndarray):\n",
    "                        self.centers = tf.get_variable(initializer=centers, name=\"centers\", dtype=tf.float32, trainable=False)\n",
    "                    else:\n",
    "                        raise ValueError(\"please provide either centers' shape or pre-defined centers matrix in numpy.ndarray\")\n",
    "\n",
    "                    batch_centers = tf.gather(self.centers, self.index, axis=0) # batch,\n",
    "                    self.center_loss = tf.nn.l2_loss(self.feature - batch_centers) # tf.reduce_sum(tf.reduce_mean(tf.square(tf.subtract(x=self.features, y=batch_centers)), axis=1))                \n",
    "\n",
    "                    # update centers using this batch samples\n",
    "                    diff = batch_centers - self.feature\n",
    "                    unique_label, unique_idx, unique_count = tf.unique_with_counts(self.index)\n",
    "                    appear_times = tf.gather(unique_count, unique_idx)\n",
    "                    appear_times = tf.reshape(appear_times, [-1, 1])\n",
    "                    diff = diff / tf.cast((1 + appear_times), tf.float32)\n",
    "                    diff = 0.5 * diff\n",
    "                    self.centers_update_op = tf.scatter_sub(self.centers, self.index, diff)\n",
    "                    self.loss = self.ce_loss + lambda_c*self.ce_loss\n",
    "\n",
    "                else:\n",
    "                    self.loss = self.ce_loss\n",
    "                    print(\"Not incorporate center_loss\")\n",
    "\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(tf.equal(x=tf.to_int32(self.probs > 0.5), y=tf.to_int32(self.y)), tf.float32))\n",
    "            # end of variable_scope(self.scope_name)\n",
    "        # end of tf.Session()\n",
    "        self.model_weights_tensors = set(self.pretrained_weights)\n",
    "        \n",
    "    def load_weights(self):\n",
    "        sess = tf.get_default_session()\n",
    "        tf.train.Saver(self.pretrained_weights).restore(sess, self.tf_checkpoint_path)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.para_dict[key]\n",
    "    \n",
    "    def dropout_layer(self, bottom, keep_prob):\n",
    "        if self.is_train == True:\n",
    "            return tf.nn.dropout(bottom, keep_prob=keep_prob)\n",
    "        else:\n",
    "            return bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_name = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myResNet(scope_name=scope_name, input_shape=input_shape, n_classes=Ytest.shape[1], n_hidden=n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorporate center_loss\n"
     ]
    }
   ],
   "source": [
    "model.build(centers=(len(Y_dict), 2048),lambda_c=0.02, keep_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess, scope_name=None):\n",
    "    if scope_name is not None:\n",
    "        var_list = [var for var in tf.global_variables() if scope_name in var.name]\n",
    "    else:\n",
    "        var_list = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in var_list])\n",
    "    not_initialized_vars = [v for (v,f) in zip(var_list, is_not_initialized) if not f]\n",
    "    if len(not_initialized_vars): \n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': input_shape,\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': n_classes,\n",
    "          'shuffle': True,\n",
    "          'img_aug': augseq,\n",
    "          'img_preprocess':  tf.contrib.keras.applications.resnet50.preprocess_input}\n",
    "\n",
    "# Generators\n",
    "training_generator   = DataGenerator(list_IDs = list(Xtrain['img_rmbg_path']), labels = Ytrain, center_IDs = Mtrain, **params)\n",
    "validation_generator = DataGenerator(list_IDs = list(Xtest['img_rmbg_path']), labels = Ytest, center_IDs = Mtest, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp0xtnbqtn\n",
      "Epoch 1 (0), 634.48 sec >> train loss: 0.5290, train accu: 0.7590, val loss: 0.4891, val accu: 0.7846\n",
      "Epoch 2 (1), 630.8 sec >> train loss: 0.4294, train accu: 0.8101, val loss: 0.4895, val accu: 0.7802\n",
      "Epoch 3 (2), 626.15 sec >> train loss: 0.3675, train accu: 0.8428, val loss: 0.5071, val accu: 0.7768\n",
      "Epoch 4 (0), 628.86 sec >> train loss: 0.3229, train accu: 0.8653, val loss: 0.5290, val accu: 0.7907\n",
      "Epoch 5 (1), 630.72 sec >> train loss: 0.2858, train accu: 0.8826, val loss: 0.5647, val accu: 0.7757\n",
      "Epoch 6 (2), 629.81 sec >> train loss: 0.2532, train accu: 0.8959, val loss: 0.5744, val accu: 0.7761\n",
      "Epoch 7 (3), 629.77 sec >> train loss: 0.2285, train accu: 0.9075, val loss: 0.5950, val accu: 0.7816\n",
      "Epoch 8 (4), 628.24 sec >> train loss: 0.2040, train accu: 0.9172, val loss: 0.6593, val accu: 0.7735\n",
      "Epoch 9 (5), 628.83 sec >> train loss: 0.1851, train accu: 0.9256, val loss: 0.6792, val accu: 0.7716\n",
      "Epoch 10 (6), 627.13 sec >> train loss: 0.1662, train accu: 0.9341, val loss: 0.6974, val accu: 0.7667\n",
      "training: 493/621\r"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model.load_weights()\n",
    "    \n",
    "    # trainable variables\n",
    "    train_vars = list()\n",
    "    for var in tf.trainable_variables():\n",
    "        if model.scope_name in var.name:\n",
    "            train_vars.append(var)\n",
    "    \n",
    "     # hyper parameters\n",
    "    batch_size = 32\n",
    "    epoch = 100\n",
    "    early_stop_patience = 10\n",
    "    min_delta = 0.0001\n",
    "    \n",
    "    # recorder\n",
    "    epoch_counter = 0\n",
    "    history = list()\n",
    "\n",
    "    # Passing global_step to minimize() will increment it at each step.\n",
    "    learning_rate = FLAG_learning_rate\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5)\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) #使用內建的 batch normalization layer, 必須執行\n",
    "    with tf.control_dependencies(update_ops):               #tf.GraphKeys.UPDATE_OPS 才會更新到 BN 層的 mean, variance\n",
    "        train_op = opt.minimize(model.loss, var_list= train_vars)\n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=2)\n",
    "    \n",
    "    checkpoint_path = os.path.join(FLAG_model_save, 'model.ckpt')\n",
    "    \n",
    "    # reset due to adding a new task\n",
    "    patience_counter = 0\n",
    "    current_best_val_accu = 0\n",
    "    \n",
    "    n_train_batch = int(Xtrain.shape[0]/batch_size)\n",
    "    n_valid_batch = int(Xtest.shape[0]/batch_size)\n",
    "    \n",
    "    initialize_uninitialized(sess)\n",
    "    \n",
    "    while(patience_counter < early_stop_patience and epoch_counter < epoch):\n",
    "        stime = time.time()\n",
    "        \n",
    "        train_loss, train_accu = 0.0, 0.0\n",
    "        for i in range(n_train_batch):\n",
    "            print('training: {0}/{1}'.format(i+1, n_train_batch), end='\\r')\n",
    "            xbatch, ybatch, mbatch = training_generator[i]\n",
    "            \n",
    "            loss, accu, _, _ = sess.run([model.loss, model.accuracy, model.centers_update_op, train_op],\n",
    "                                       feed_dict={model.x: xbatch,\n",
    "                                                 model.y: ybatch,\n",
    "                                                 model.index: mbatch,\n",
    "                                                 model.is_train: True})\n",
    "            train_loss += loss\n",
    "            train_accu += accu\n",
    "        \n",
    "        train_loss = train_loss/n_train_batch\n",
    "        train_accu = train_accu/n_train_batch\n",
    "        \n",
    "        valid_loss, valid_accu = 0.0, 0.0\n",
    "        for i in range(n_valid_batch):\n",
    "            print('validating: {0}/{1}'.format(i+1, n_valid_batch), end='\\r')\n",
    "            xbatch, ybatch, mbatch = validation_generator[i]\n",
    "            \n",
    "            loss, accu, = sess.run([model.loss, model.accuracy],\n",
    "                                       feed_dict={model.x: xbatch,\n",
    "                                                 model.y: ybatch,\n",
    "                                                 model.index: mbatch,\n",
    "                                                 model.is_train: False})\n",
    "            valid_loss += loss\n",
    "            valid_accu += accu\n",
    "        \n",
    "        valid_loss = valid_loss/n_valid_batch\n",
    "        valid_accu = valid_accu/n_valid_batch\n",
    "        \n",
    "         # early stopping check\n",
    "        if (valid_accu - current_best_val_accu) > min_delta:\n",
    "            current_best_val_accu = valid_accu\n",
    "            patience_counter = 0\n",
    "\n",
    "#             para_dict = sess.run(model.para_dict)\n",
    "#             np.save(os.path.join(FLAG_save_dir, \"para_dict.npy\"), para_dict)\n",
    "#             print(\"save in %s\" % os.path.join(FLAG_model_save, \"para_dict.npy\"))\n",
    "            saver.save(sess, checkpoint_path, global_step=epoch_counter)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        training_generator.on_epoch_end()\n",
    "        epoch_counter += 1\n",
    "        \n",
    "        print(\"Epoch %s (%s), %s sec >> train loss: %.4f, train accu: %.4f, val loss: %.4f, val accu: %.4f\"% (epoch_counter, patience_counter, round(time.time()-stime,2), train_loss, train_accu, valid_loss, valid_accu))\n",
    "        history.append([train_loss, train_accu, valid_loss, valid_accu])\n",
    "        \n",
    "        if epoch_counter % 10 == 0:\n",
    "            df = pd.DataFrame(history)\n",
    "            df.columns = ['train_loss', 'train_accu', 'val_loss', 'val_accu']\n",
    "            df[['train_loss', 'val_loss']].plot()\n",
    "            plt.savefig(os.path.join(FLAG_model_save, 'loss.png'))\n",
    "            plt.close()\n",
    "            df[['train_accu', 'val_accu']].plot()\n",
    "            plt.savefig(os.path.join(FLAG_model_save, 'accu.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            df.to_csv(os.path.join(FLAG_model_save, \"history.csv\"))\n",
    "    saver.save(sess, checkpoint_path, global_step=epoch_counter)\n",
    "    \n",
    "    centers = sess.run(model.centers)\n",
    "    np.save(arr=centers,file=os.path.join(FLAG_model_save,\"centers.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Generators\n",
    "#     training_generator   = DataGenerator(list_IDs = list(Xtrain['img_rmbg_path']), labels = Ytrain, center_IDs = Mtrain, **params)\n",
    "#     validation_generator = DataGenerator(list_IDs = list(Xtest['img_rmbg_path']), labels = Ytest, center_IDs = Mtest, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_input = Input(shape=input_shape)\n",
    "# extractor = ResNet50(input_tensor=img_input, include_top=False, weights='imagenet', pooling='avg')\n",
    "# dropout = Dropout(rate=0.5)(extractor.output)\n",
    "# dense1 = Dense(1000, activation='relu', name='dense1')(dropout)\n",
    "# dense1 = Dropout(rate=0.5)(dense1)\n",
    "# output = Dense(n_classes, activation='sigmoid', name='output_layer')(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'dim': input_shape,\n",
    "#           'batch_size': batch_size,\n",
    "#           'n_classes': n_classes,\n",
    "#           'shuffle': True,\n",
    "#           'img_aug': augseq,\n",
    "#           'img_preprocess': preprocess_input}\n",
    "    \n",
    "# if isCenterloss:\n",
    "#     lambda_c = 0.02\n",
    "#     input_target = Input(shape=(1,)) # single value ground truth labels as inputs\n",
    "#     centers = Embedding(input_dim=1, input_length=len(Y_dict), output_dim=int(extractor.output.get_shape()[1]))(input_target)\n",
    "#     l2_loss = Lambda(lambda x: K.sum(K.square(x[0]-x[1][:,0]),1,keepdims=True),name='l2_loss')([extractor.output, centers])\n",
    "#     model = Model(inputs=[img_input,input_target],outputs=[output, l2_loss])        \n",
    "#     model.compile(optimizer=Adam(lr=1e-5, beta_1=0.5), \n",
    "#                              loss=[\"binary_crossentropy\", lambda y_true,y_pred: y_pred],\n",
    "#                              loss_weights=[1,lambda_c],\n",
    "#                              metrics=['accuracy'])\n",
    "    \n",
    "#     # Generators\n",
    "#     training_generator   = DataGenerator(list_IDs = list(Xtrain['img_rmbg_path']), labels = Ytrain, center_IDs = Mtrain, **params)\n",
    "#     validation_generator = DataGenerator(list_IDs = list(Xtest['img_rmbg_path']), labels = Ytest, center_IDs = Mtest, **params)\n",
    "\n",
    "# else:\n",
    "#     model = Model(inputs=img_input, outputs=output)\n",
    "#     model.compile(optimizer=Adam(lr=1e-5, beta_1=0.5), \n",
    "#                   loss=\"binary_crossentropy\",\n",
    "#                   metrics=[\"accuracy\"])\n",
    "    \n",
    "#         # Generators\n",
    "#     training_generator   = DataGenerator(list_IDs = list(Xtrain['img_rmbg_path']), labels = Ytrain, center_IDs = None, **params)\n",
    "#     validation_generator = DataGenerator(list_IDs = list(Xtest['img_rmbg_path']), labels = Ytest, center_IDs = None, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_logger = keras.callbacks.CSVLogger(os.path.join(FLAG_model_save, 'training.log'))\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(FLAG_model_save, 'model.h5'), \n",
    "#                                              monitor='val_loss', \n",
    "#                                              verbose=1, \n",
    "#                                              save_best_only=True,\n",
    "#                                              save_weights_only=False,\n",
    "#                                              mode='min',\n",
    "#                                              period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Train model on dataset\n",
    "# model.fit_generator(generator=training_generator,\n",
    "#                    validation_data=validation_generator,\n",
    "#                    use_multiprocessing=True,\n",
    "#                    steps_per_epoch=Xtrain.shape[0]/batch_size, \n",
    "#                    validation_steps=Xtest.shape[0]/batch_size,\n",
    "#                    workers=6,\n",
    "#                    epochs=50,\n",
    "#                    callbacks=[csv_logger, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
